---
title: "Interest Rates"
format: html
editor: visual
---

# Interest Rates Model

## Setup

### Load packages

```{r}
library(vars)  
library(mFilter)  
library(tseries)  
library(TSstudio)  
library(forecast)
library(tidyverse)
library(here)
library(readxl)
```

### Import data

```{r}
# Import data
newfinal_monthly_all <- read_excel(here("Data", "newfinal_monthly_all.xlsx"), 
    col_types = c("date", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
```

### Create functions and lists

```{r}
# Create function: create_ts
create_ts <- function(data, column, time_period, frequency = 12) {
  start <- time_period$start
  end <- time_period$end
  ts(data[[column]], start = start, end = end, frequency = frequency)
}
```

```{r}
# Create time period lists
time_period_full <- list(start = c(2013, 4), end = c(2024, 8))
time_period_old <- list(start = c(2013,4), end = c(2023,3))
time_period_actual <- list(start = c(2023, 4), end = c(2024, 3))
```

### Define variables

```{r}
# Define variables
CapRate <- create_ts(newfinal_monthly_all, "cap", time_period_full)
DGS10 <- create_ts(newfinal_monthly_all, "DGS10", time_period_full)
DFF <- create_ts(newfinal_monthly_all, "DFF", time_period_full)
lnDGS10 <- create_ts(newfinal_monthly_all, "lnDGS10", time_period_full)
lnDFF <- create_ts(newfinal_monthly_all, "lnDFF", time_period_full)
```

```{r}
# Create difference variables
DGS10_d2 <- diff(DGS10, differences = 2)
DFF_d2 <- diff(DFF, differences = 2)
```

```{r}
# Define new differenced variables
DGS10_d2 <- ts(DGS10_d2, start = c(2013, 4), end = c(2024, 8), frequency = 12)
DFF_d2 <- ts(DFF_d2, start = c(2013, 4), end = c(2024, 8), frequency = 12)
```

```{r}
# Add new differenced variables to dataframe
newfinal_monthly_all$DGS10_d2 <- DGS10_d2
newfinal_monthly_all$DFF_d2 <- DFF_d2
```

## Subset data

My first step is *replicating the original forecast*. I need a shortened data set with just that time segment.

### Old data

This is the time segment I used for my original analysis. (4/13-3/23)

```{r}
# Subset dataframe to make one with shortened, original data
olddata <- subset(newfinal_monthly_all, select = c(observation_date, cap, DGS10, DFF, lnDGS10, lnDFF), observation_date < as.Date("2023-04-01"))
colnames(olddata) = c("observation_date", "CapRate", "DGS10", "DFF", "lnDGS10", "lnDFF")
```

```{r}
# Define new matrix variables with old timeframe
oldCapRate <- ts(olddata$CapRate, start = c(2013, 4), end = c(2023, 3), frequency = 12)
oldDGS10 <- ts(olddata$DGS10, start = c(2013, 4), end = c(2023, 3), frequency = 12)
oldDFF <- ts(olddata$DFF, start = c(2013, 4), end = c(2023, 3), frequency = 12)
oldlnDGS10 <- ts(olddata$lnDGS10, start = c(2013, 4), end = c(2023, 3), frequency = 12)
oldlnDFF <- ts(olddata$lnDFF, start = c(2013, 4), end = c(2023, 3), frequency = 12)
# Create difference variables (old)
oldDGS10_d2 <- diff(oldDGS10, differences = 2)
oldDFF_d2 <- diff(oldDFF, differences = 2)
# Define new variables (old)
oldDGS10_d2 <- ts(oldDGS10_d2, start = c(2013, 4), end = c(2023, 3), frequency = 12)
oldDFF_d2 <- ts(oldDFF_d2, start = c(2013, 4), end = c(2023, 3), frequency = 12)
```

### Actual data

This is the time segment between my original analysis and my new data.

```{r}
# Make subset for 'actual' data
actualdata <- subset(newfinal_monthly_all, select = c(observation_date, cap, DGS10, DFF, lnDGS10, lnDFF), observation_date > as.Date("2023-03-01") & observation_date <= as.Date("2024-03-01"))
colnames(actualdata) = c("observation_date", "CapRate", "DGS10", "DFF", "lnDGS10", "lnDFF")
actualdata$observation_date <- as.Date(actualdata$observation_date)
```

```{r}
# Define new matrix variables with 'actual' timeframe
actualCapRate <- ts(actualdata$CapRate, start = c(2023, 4), end = c(2024, 3), frequency = 12)
actualDGS10 <- ts(actualdata$DGS10, start = c(2023, 4), end = c(2024, 3), frequency = 12)
actualDFF <- ts(actualdata$DFF, start = c(2023, 4), end = c(2024, 3), frequency = 12)
actuallnDGS10 <- ts(actualdata$lnDGS10, start = c(2023, 4), end = c(2024, 3), frequency = 12)
actuallnDFF <- ts(actualdata$lnDFF, start = c(2023, 4), end = c(2024, 3), frequency = 12)
# Create difference variables (old)
actualDGS10_d2 <- diff(actualDGS10, differences = 2)
actualDFF_d2 <- diff(actualDFF, differences = 2)
# Define new variables (old)
actualDGS10_d2 <- ts(actualDGS10_d2, start = c(2023, 4), end = c(2024, 3), frequency = 12)
actualDFF_d2 <- ts(actualDFF_d2, start = c(2023, 4), end = c(2024, 3), frequency = 12)
```

## Build model (old)

```{r}
# Make new dataframe with only model variables
olddf <- cbind(oldCapRate, oldDGS10_d2, oldDFF_d2)
colnames(olddf) <- cbind("CapRate", "DGS10", "DFF")
```

```{r}
# Determine lag order
lagselect <- VARselect(olddf, lag.max = 15, type = "const")
lagselect$selection
```

```{r}
# Create model
oldModel <- VAR(olddf, p = 4, type = "const", season = NULL, exog = NULL)
```

## Forecast (old)

```{r}
originalforecast <- predict(oldModel, n.ahead = 12, ci = 0.95)
```

### Extract forecast values (old)

```{r}
# Import csv of forecast values
oldforecast <- read_excel("C:/Users/kschmitt1/Knipp Wolf NLG Dropbox/Knipp Group Team Folder/5 - STAFF/3 - STAFF/KSchmitt/Research Reports/Interest Rates (General Report 1)/oldforecast.xlsx")
oldforecast$observation_date <- as.Date(oldforecast$observation_date)
```

### Compare old forecast to new values

#### Line graph

##### Cap rate

```{r}
ggplot() +
geom_line(data = oldforecast, aes(x = observation_date, y = CapRatefcst), color = "blue") +
geom_line(data = actualdata, aes(x = observation_date, y = CapRate), color = "red")
```

##### DGS10

```{r}
ggplot() +
geom_line(data = oldforecast, aes(x = observation_date, y = DGS10fcst), color = "blue") +
geom_line(data = actualdata, aes(x = observation_date, y = DGS10), color = "red")
```

##### DFF

```{r}
ggplot() +
geom_line(data = oldforecast, aes(x = observation_date, y = DFFfcst), color = "blue") +
geom_line(data = actualdata, aes(x = observation_date, y = DFF), color = "red")
```

#### Absolute difference

```{r}
# Create new df for error measurements
error <- data.frame(observation_date=as.Date(oldforecast$observation_date))
## Absolute differences
error$CapRate_absolute_difference=abs(c(oldforecast$CapRatefcst-actualdata$CapRate))
error$DGS10_absolute_difference=abs(c(oldforecast$DGS10fcst-actualdata$DGS10))
error$DFF_absolute_difference=abs(c(oldforecast$DFFfcst-actualdata$DFF))
```

#### Mean Absolute Percentage Error (MAPE)

```{r}
## MAPE
error$CapRatemape=mean(abs((actualdata$CapRate-oldforecast$CapRatefcst)/oldforecast$CapRatefcst))
error$DGS10mape=mean(abs((actualdata$DGS10-oldforecast$DGS10fcst)/oldforecast$DGS10fcst))
error$DFFmape=mean(abs((actualdata$DFF-oldforecast$DFFfcst)/oldforecast$DFFfcst))
```

## Build model (new)

```{r}
# Make new dataframe with only model variables
newdf <- cbind(CapRate, DGS10_d2, DFF_d2)
colnames(newdf) <- cbind("CapRate", "DGS10", "DFF")
```

```{r}
# Determine lag order
lagselect <- VARselect(newdf, lag.max = 15, type = "const")
lagselect$selection
```

```{r}
# Create model
newModel <- VAR(newdf, p = 4, type = "const", season = NULL, exog = NULL)
```

## Forecast (new)

```{r}
newforecast <- predict(newModel, n.ahead = 12, ci = 0.95)
```

### Extract forecast values (new)

```{r}
# Import csv of forecast values
newforecast <- read_excel("C:/Users/kschmitt1/Knipp Wolf NLG Dropbox/Knipp Group Team Folder/5 - STAFF/3 - STAFF/KSchmitt/Research Reports/Interest Rates (General Report 1)/newforecast.xlsx")
newforecast$observation_date <- as.Date(oldforecast$observation_date)
```

## Model Diagnostics

### Autocorrelation

```{r}
serial <- serial.test(newModel, lags.pt = 5, type = "PT.asymptotic")
serial
```

-   Residuals should ideally be non-autocorrelated
    -   Assumption: residuals are white noise uncorrelated with previous periods
    -   Results can change with lag order, so it is best to experiment with different lag order values
    -   *K: I'm not sure how they chose the lag order value as 5 here since it was 2 in the last step*
    -   *K: I'm also not sure how to read residuals for signs of autocorrelation*

### Heteroscedasticity

```{r}
Arch1 <- arch.test(newModel, lags.multi = 15, multivariate.only = TRUE)
Arch1
```

-   ARCH effects: clustered volatility areas in a time series

    -   Volatility in these areas can change the variance of residuals, violating the assumption of constant variance. Constant volatility models can account for this

        -   If null is not rejected by this test:

            -   No ARCH effects in model

            -   No heteroscedasticity

-   Results may change with lag order

# CURRENT PROBLEMS

-   I need to make sure that the model fitting and testing steps are correct for the new data
-   error on DGS10 and DFF are horrible.
    -   what are the theoretical reasons for this, if any?
        -   my model is really just to predict cap rates, not these variables, but it does kind of do that and the predictions of those impact the cap rate predictions.
    -   did I mess something up? or is this fine? again, I don't think this model is supposed to predict those variables
-   need to figure out Autocorrelation, see notes there
-   update test branch-1
